# Global configuration for all repository processes.

# General settings
general:
  seed: 42 # Random seed for reproducibility
  gpus: 4 # No. of GPUs available for parallelization
  tmp: "temp" # Directory to store temporary files, throwaway scripts, etc.
  logs: 
    dir: ".logs" # `null` to print logs or "<directory>" to save them
    level: "DEBUG" # "CRITICAL", "ERROR", "WARNING", "INFO", "DEBUG", "NOTSET"

# File and directory paths for all processes
paths:
  philpapers:
    metadata: "datasets/raw/papers/metadata" # Local path to store paper metadata from Philpapers.org. If filepath: use exact file, if directory path: use lastest file
    pdfs: "datasets/raw/papers/pdfs" # Local directory to store pdfs downloaded from Philpapers.org
    docling:
      raw: "datasets/interim/papers/docling/raw" # Local directory to store pdfs docling'd but not yet cleaned
      cleaned: "datasets/processed/papers/cleaned" # Local directory to store papers docling'd + cleaned
  workshop:
    sample: "datasets/processed/argument_mining/workshop_sample/n200" # Local directory used for the workshop sample
    annotations:
      large_json_maps: "datasets/processed/argument_mining/converted_workshop_annotations/large_json" # Local directory to store "large" workshop annotations in json format
      small_json_maps: "datasets/processed/argument_mining/converted_workshop_annotations/small_json" # Local directory to store "small" workshop annotations in json format
      large_argdown_maps: "datasets/processed/argument_mining/converted_workshop_annotations/large_argdown" # Local directory to store "large" workshop annotations in argdown format
      small_argdown_maps: "datasets/processed/argument_mining/converted_workshop_annotations/small_argdown" # Local directory to store "small" workshop annotations in argdown format
    argilla:
      suggestions:
        raw: "datasets/raw/argument_mining/workshop_model_suggestions/raw_responses" # Local directory to store unparsed LLM argmap output
        cleaned: "datasets/interim/argument_mining/workshop_model_suggestions/extracted_suggestions" # Local directory to store parsed LLM argmap output
  models:
    end2end: # End-to-end LLM argument mining models
      base:
        dir: "models/meta_llama_3.1_8B/Meta-Llama-3.1-8B-Instruct-bnb-4bit" # Local directory where model is stored
        hf: "unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit" # Hugging Face directory for reference if not found locally
      finetune: 
        dir: "models/meta_llama_3.1_8B/finetune" # Local directory model is stored (PEFT LoRA adapter weights only)
        hf: "andrewelawrence/AMwithLLMs-Meta-Llama-3.1-8B-Instruct-bnb-4bit" # Hugging Face directory for reference if not found locally
      embedder:
        dir: "models/qwen3_embedding_0.6B" # Local directory where model is stored
        hf: "Qwen/Qwen3-Embedding-0.6B" # Hugging face directory for reference if not found locally
    adur: # Argument Discourse Unit recognition
      model_1:
        dir: "models/roberta_argument" # Local directory where model is stored
        hf: "chkla/roberta-argument" # Hugging face directory for reference if not found locally
      model_2:
        dir: "models/sam_adur_sciarg" # Local directory where model is stored
        hf: "ArneBinder/sam-adur-sciarg" # Hugging face directory for reference if not found locally
    are: # Argumentative relation extraction
      model_1:
        dir: "models/argmining_en_ari_aif_roberta_l" # Local directory where model is stored
        hf: "raruidol/ArgumentMining-EN-ARI-AIF-RoBERTa_L" # Hugging face directory for reference if not found locally
      model_2:
        dir: "models/sam_are_sciarg" # Local directory where model is stored
        hf: "ArneBinder/sam-are-sciarg" # Hugging face directory for reference if not found locally
  snowball:
    phase_1:
      outputs:
        end2end:
          standard: 
            zero-shot: "datasets/interim/argument_mining/snowball_phase_1/end2end/standard/zero-shot" # Raw generation outputs for zero-shot standard prompting
            one-shot: "datasets/interim/argument_mining/snowball_phase_1/end2end/standard/one-shot" # Raw generation outputs for one-shot standard prompting
            few-shot: "datasets/interim/argument_mining/snowball_phase_1/end2end/standard/few-shot" # Raw generation outputs for few-shot standard prompting
          standard_rag: "datasets/interim/argument_mining/snowball_phase_1/end2end/standard_rag" # Raw generation outputs for standard RAG prompting
          cot: "datasets/interim/argument_mining/snowball_phase_1/end2end/cot" # Raw generation outputs for CoT prompting
          rag_cot: "datasets/interim/argument_mining/snowball_phase_1/end2end/rag_cot" # Raw generation outputs for RAG+CoT prompting
        adur: "datasets/interim/argument_mining/snowball_phase_1/adur" # Raw ADUR pipeline outputs
        are: "datasets/interim/argument_mining/snowball_phase_1/are" # Raw ARE pipeline outputs
      parsed:
        end2end:
          standard: "datasets/processed/argument_mining/snowball_phase_1/end2end/standard" # Parsed argument maps for standard prompting
          standard_rag: "datasets/processed/argument_mining/snowball_phase_1/end2end/standard_rag" # Parsed argument maps for standard RAG prompting
          cot: "datasets/processed/argument_mining/snowball_phase_1/end2end/cot" # Parsed argument maps for CoT prompting
          rag_cot: "datasets/processed/argument_mining/snowball_phase_1/end2end/rag_cot" # Parsed argument maps for RAG+CoT prompting
        adur: "datasets/processed/argument_mining/snowball_phase_1/adur" # Parsed argument maps from ADUR pipeline
        are: "datasets/processed/argument_mining/snowball_phase_1/are" # Parsed argument maps from ARE pipeline
      valid: "datasets/processed/argument_mining/snowball_sampling/phase_1_workshop_sample" # Argument map pipeline results for the annotation comparision set
      sample: "datasets/processed/argument_mining/snowball_sampling/phase_1_small_sample" # Argument map pipeline results for the random validation
      prompts: 
        x_shot_examples: # Local directory containing arguments mined from a paper for use as annotation examples in one- or few-shot annotation prompting
          paper: "src/moralkg/snowball/phase_1/prompts/x_shot_examples/SCHFAT-43_cleaned.md" # Local filepath to a single paper
          main_arg_map: "src/moralkg/snowball/phase_1/prompts/x_shot_examples/SCHFAT-43_main.json" # Local filepath to the main argument map for the example paper, in json format
          extra_arg_map: "src/moralkg/snowball/phase_1/prompts/x_shot_examples/SCHFAT-43_extra.json" # Local filepath to map of extra arguments for the example paper, in json format
        templates: # Directory of templates for constructing LLM prompts via script
          standard: "src/moralkg/snowball/phase_1/prompts/templates/standard"
          standard_rag: "src/moralkg/snowball/phase_1/prompts/templates/standard_rag"
          cot: "src/moralkg/snowball/phase_1/prompts/templates/cot"
          rag_cot: "src/moralkg/snowball/phase_1/prompts/templates/rag_cot"
        meta_llama_3:
          standard: 
            zero-shot: "src/moralkg/snowball/phase_1/prompts/meta_llama_3.1_8B_Instruct/standard/zero-shot" # LLM system and user prompts for the zero-shot standard pipeline
            one-shot: "src/moralkg/snowball/phase_1/prompts/meta_llama_3.1_8B_Instruct/standard/one-shot" # LLM system and user prompts for the one-shot standard pipeline
            few-shot: "src/moralkg/snowball/phase_1/prompts/meta_llama_3.1_8B_Instruct/standard/few-shot" # LLM system and user prompts for the few-shot standard pipeline
          standard_rag: "src/moralkg/snowball/phase_1/prompts/meta_llama_3.1_8B_Instruct/standard_rag" # LLM system and user prompts for the standard RAG pipelines
          cot: "src/moralkg/snowball/phase_1/prompts/meta_llama_3.1_8B_Instruct/cot" # LLM system and user prompts for the CoT pipeline
          rag_cot: "src/moralkg/snowball/phase_1/prompts/meta_llama_3.1_8B_Instruct/cot_rag" # LLM system and user prompts for the RAG+CoT pipeline
    phase_2:
      sample: "datasets/processed/argument_mining/snowball_sampling/phase_2_large_sample"
  figures:
    philpapers: "figures/phil_papers"
    workshop: "figures/mere_workshop"
    snowball: "figures/snowball_sampling"
      
# Philpapers.org dataset creation process settings & data locations
philpapers:
  metadata:
    schema: # OAI Schema to parse metadata OAI XML directory
      mappings: 
        dc:title: "title"
        dc:type: "type"
        dc:creator: "authors" # Semicolon-separated, (last name, first name)
        dc:subject: "subjects" # Semicolon-separated
        dc:date: "year"
        dc:identifier: "identifier-url"
        dc:language: "language"
      special:
        identifier:
          xpath: "header/identifier"
          pattern: "oai:philpapers.org/rec/(?P<id>.+)$"
          field: "identifier"
  papers:
    grobid: # Grobid process config. NOTE: probably can delete this + grobid references as we never use it.
      dir: "datasets/interim/papers/grobid"
      server: "http://localhost:8070"
      batch_size: 1000
      sleep_time: 3
      timeout: 60
      coordinates: ["persName", "figure", "ref", "biblStruct", "formula", "s"]

# MERe Workshop
workshop:
  annotations: 
    use: "large" # What annotations to consider in pipelines: "large" or "both"

# Argument Mining schema
argmining:
  schema: "src/moralkg/argmining/schemas/argmining.json" # Filepath to JSON argument map schema

# Snowball Sampling
snowball:
  annotations:
    holdout: 0.20 # Split between validation and test (holdout) sets. NOTE: there is no "train" set as we're just running evals on the human annotations.
  phase_1:
    eval:
      fuzzy_thr: 0.70 # Threshold of fuzzy similarity required to pass in order to be considered the "same" ADU.
      loss:
        w: [0.25, 0.25, 0.25, 0.25] # Weighting of the 4 eval metrics: [Fuzzy-match F1 (ADU similarity), Relation-type F1 (relation similarity), Count Error (On ADUs and Relations), Attributed Graph Edit Distance]
    hparams:
      end2end: # End-to-end LLM argument mining models
        decoding:
          temperature: 0.7 
          max_new_tokens: none # TODO
        rag:
          embedder_dim: 1024
          chunk_size: none # TODO 
          chunk_overlap: [100, 150] # TODO
          top_k: 10 # TODO
      adur: # Argument Discourse Unit 
        major_adu_extraction: ["centroid", "pairwise"] # Method of major claim extraction: ["centroid", "pairwise"]
  phase_2:
    distance_thr: 0.20 # Cosine distance threshold to cross in order to be considered similar
    sample_size: 1000 # Size of sample argument maps to create 
    rand_sample_size: 20
    holdout: 0.20
    hparams:
      C: [0.001, 0.1, 1, 10] # TODO
